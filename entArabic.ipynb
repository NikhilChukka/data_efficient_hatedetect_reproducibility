{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29ad3c2a-59a5-49eb-b622-2c6a8c98db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0635c7b1-5d37-40ab-aa03-2fa451229399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "class HateSpeechEntailmentDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str,\n",
    "        tokenizer: AutoTokenizer,\n",
    "        label_prompts: Dict[int, str],\n",
    "        max_length: int = 128\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Dataset class for entailment-style hate speech detection\n",
    "        \n",
    "        Args:\n",
    "            data_path: Path to TSV file with 'post' and 'class' columns\n",
    "            tokenizer: HuggingFace tokenizer\n",
    "            label_prompts: Dictionary mapping labels to prompt text\n",
    "            max_length: Maximum sequence length\n",
    "        \"\"\"\n",
    "        # Read TSV file\n",
    "        print(f\"Loading data from {data_path}\")\n",
    "        df = pd.read_csv(data_path, sep='\\t')\n",
    "        self.texts = df['post'].astype(str).tolist()\n",
    "        self.labels = df['label'].astype(int).tolist()\n",
    "        print(f\"Loaded {len(self.texts)} examples\")\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.label_prompts = label_prompts\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Create positive and negative pairs\n",
    "        pos_prompt = self.label_prompts[label]\n",
    "        neg_prompt = self.label_prompts[1 - label]\n",
    "        \n",
    "        # Tokenize positive pair\n",
    "        pos_encoding = self.tokenizer(\n",
    "            text,\n",
    "            pos_prompt,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Tokenize negative pair\n",
    "        neg_encoding = self.tokenizer(\n",
    "            text,\n",
    "            neg_prompt, \n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'pos_input_ids': pos_encoding['input_ids'].squeeze(),\n",
    "            'pos_attention_mask': pos_encoding['attention_mask'].squeeze(),\n",
    "            'neg_input_ids': neg_encoding['input_ids'].squeeze(),\n",
    "            'neg_attention_mask': neg_encoding['attention_mask'].squeeze(),\n",
    "            'label': torch.tensor(1)  # Positive pair should entail\n",
    "        }\n",
    "\n",
    "class HateSpeechEntailmentModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = 'cardiffnlp/twitter-xlm-roberta-base-sentiment',\n",
    "        num_labels: int = 2\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Model class for entailment-style hate speech detection\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=num_labels\n",
    "        )\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        return outputs.logits\n",
    "\n",
    "# Add this to your imports\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    num_epochs: int = 5,\n",
    "    model_save_path: str = None\n",
    ") -> None:\n",
    "    \"\"\"Train model with validation monitoring\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_val_f1 = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Create progress bar for training\n",
    "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "        \n",
    "        for batch in train_pbar:\n",
    "            pos_input_ids = batch['pos_input_ids'].to(device)\n",
    "            pos_attention_mask = batch['pos_attention_mask'].to(device)\n",
    "            neg_input_ids = batch['neg_input_ids'].to(device)\n",
    "            neg_attention_mask = batch['neg_attention_mask'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass for both positive and negative pairs\n",
    "            pos_logits = model(pos_input_ids, pos_attention_mask)\n",
    "            neg_logits = model(neg_input_ids, neg_attention_mask)\n",
    "            \n",
    "            # Calculate loss\n",
    "            pos_labels = torch.ones(pos_logits.size(0), dtype=torch.long).to(device)\n",
    "            neg_labels = torch.zeros(neg_logits.size(0), dtype=torch.long).to(device)\n",
    "            \n",
    "            pos_loss = criterion(pos_logits, pos_labels)\n",
    "            neg_loss = criterion(neg_logits, neg_labels)\n",
    "            loss = pos_loss + neg_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        print(\"\\nRunning validation...\")\n",
    "        val_acc, val_f1 = evaluate(model, val_loader, device)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Average Loss: {avg_loss:.4f}\")\n",
    "        print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "        print(f\"Validation F1: {val_f1:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if model_save_path and val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Saved best model with F1: {val_f1:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual = []\n",
    "    \n",
    "    # Add progress bar for evaluation\n",
    "    eval_pbar = tqdm(dataloader, desc='Evaluating')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in eval_pbar:\n",
    "            pos_input_ids = batch['pos_input_ids'].to(device)\n",
    "            pos_attention_mask = batch['pos_attention_mask'].to(device)\n",
    "            \n",
    "            logits = model(pos_input_ids, pos_attention_mask)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            actual.extend(batch['label'].cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = sum(p == a for p, a in zip(predictions, actual)) / len(actual)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    tp = sum((p == 1 and a == 1) for p, a in zip(predictions, actual))\n",
    "    fp = sum((p == 1 and a == 0) for p, a in zip(predictions, actual))\n",
    "    fn = sum((p == 0 and a == 1) for p, a in zip(predictions, actual))\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab011b7-3a7f-4559-bd03-63d529be7ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Initializing tokenizer and model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading data from data/multilingual/train_arab.tsv\n",
      "Loaded 5147 examples\n",
      "Loading test data...\n",
      "Loading data from data/multilingual/test_arab.tsv\n",
      "Loaded 271 examples\n",
      "Creating dataloaders...\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [Train]: 100%|██████████| 322/322 [02:08<00:00,  2.50it/s, loss=0.1712]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00, 15.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n",
      "Average Loss: 0.8069\n",
      "Validation Accuracy: 0.8967\n",
      "Validation F1: 0.9455\n",
      "Saved best model with F1: 0.9455\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 [Train]: 100%|██████████| 322/322 [02:07<00:00,  2.52it/s, loss=0.8235]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00, 15.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/3\n",
      "Average Loss: 0.5719\n",
      "Validation Accuracy: 0.9114\n",
      "Validation F1: 0.9537\n",
      "Saved best model with F1: 0.9537\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 [Train]: 100%|██████████| 322/322 [02:07<00:00,  2.52it/s, loss=0.4953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00, 15.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/3\n",
      "Average Loss: 0.4335\n",
      "Validation Accuracy: 0.8487\n",
      "Validation F1: 0.9182\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluating best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:01<00:00, 15.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Results:\n",
      "Accuracy: 0.9114\n",
      "F1 Score: 0.9537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#main for latent hatred dataset\n",
    "def main():\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Define paths\n",
    "    train_path = \"data/multilingual/train_arab.tsv\"\n",
    "    test_path = \"data/multilingual/test_arab.tsv\"\n",
    "    model_save_path = \"saved_models/best_model.pth\"\n",
    "    \n",
    "    # Create directory for saved models if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "    \n",
    "    # Define label prompts\n",
    "    label_prompts = {\n",
    "        0: \"هذا المنشور يحتوي على كلمات عادية\",\n",
    "        1: \"تحتوي هذه المشاركة على خطاب يحض على الكراهية\"\n",
    "    }\n",
    "    \n",
    "    # Initialize tokenizer and model\n",
    "    print(\"Initializing tokenizer and model...\")\n",
    "    model_name = 'xlm-roberta-base'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = HateSpeechEntailmentModel(model_name).to(device)\n",
    "    \n",
    "    # Create datasets\n",
    "    print(\"Loading training data...\")\n",
    "    train_dataset = HateSpeechEntailmentDataset(\n",
    "        data_path=train_path,\n",
    "        tokenizer=tokenizer,\n",
    "        label_prompts=label_prompts\n",
    "    )\n",
    "    \n",
    "    print(\"Loading test data...\")\n",
    "    test_dataset = HateSpeechEntailmentDataset(\n",
    "        data_path=test_path,\n",
    "        tokenizer=tokenizer,\n",
    "        label_prompts=label_prompts\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders\n",
    "    print(\"Creating dataloaders...\")\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    # Train model\n",
    "    train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        optimizer,\n",
    "        device,\n",
    "        num_epochs=3,\n",
    "        model_save_path=model_save_path\n",
    "    )\n",
    "    \n",
    "    # Load best model and evaluate on test set\n",
    "    print(\"\\nEvaluating best model...\")\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    test_acc, test_f1 = evaluate(model, test_loader, device)\n",
    "    print(f\"\\nFinal Test Results:\")\n",
    "    print(f\"Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"F1 Score: {test_f1:.4f}\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
