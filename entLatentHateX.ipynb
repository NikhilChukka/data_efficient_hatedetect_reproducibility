{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29ad3c2a-59a5-49eb-b622-2c6a8c98db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9336f7af-77f5-4502-9dc3-a9fac134185e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>such  racism goy  there is only       shared h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt and the color of facist fiction is white</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>girl  sure you can wait   must  coz your allah...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who are their supporters black people or white...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you re wrong i m white and my kids are white</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14268</th>\n",
       "      <td>not only secure the border  but restrict all i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14269</th>\n",
       "      <td>the white genocide continues   white race now ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14270</th>\n",
       "      <td>so dan carlin is uninformed about the nordics ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14271</th>\n",
       "      <td>by western men  i mean white western men   don...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14272</th>\n",
       "      <td>goy is hebrew for nation   do you people fact ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14273 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    post  class\n",
       "0      such  racism goy  there is only       shared h...      1\n",
       "1            rt and the color of facist fiction is white      1\n",
       "2      girl  sure you can wait   must  coz your allah...      0\n",
       "3      who are their supporters black people or white...      0\n",
       "4           you re wrong i m white and my kids are white      0\n",
       "...                                                  ...    ...\n",
       "14268  not only secure the border  but restrict all i...      1\n",
       "14269  the white genocide continues   white race now ...      1\n",
       "14270  so dan carlin is uninformed about the nordics ...      1\n",
       "14271  by western men  i mean white western men   don...      0\n",
       "14272  goy is hebrew for nation   do you people fact ...      0\n",
       "\n",
       "[14273 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train1 = pd.read_csv(\"data/latenthatred/latent_train.tsv\", sep='\\t')\n",
    "df_test1 = pd.read_csv(\"data/latenthatred/latent_test.tsv\", sep='\\t')\n",
    "df_train1['class'].value_counts().sum()+ df_test1['class'].value_counts().sum()\n",
    "df_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0635c7b1-5d37-40ab-aa03-2fa451229399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "class HateSpeechEntailmentDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str,\n",
    "        tokenizer: AutoTokenizer,\n",
    "        label_prompts: Dict[int, str],\n",
    "        max_length: int = 128\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Dataset class for entailment-style hate speech detection\n",
    "        \n",
    "        Args:\n",
    "            data_path: Path to TSV file with 'post' and 'class' columns\n",
    "            tokenizer: HuggingFace tokenizer\n",
    "            label_prompts: Dictionary mapping labels to prompt text\n",
    "            max_length: Maximum sequence length\n",
    "        \"\"\"\n",
    "        # Read TSV file\n",
    "        print(f\"Loading data from {data_path}\")\n",
    "        df = pd.read_csv(data_path, sep='\\t')\n",
    "        self.texts = df['post'].astype(str).tolist()\n",
    "        self.labels = df['class'].astype(int).tolist()\n",
    "        print(f\"Loaded {len(self.texts)} examples\")\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.label_prompts = label_prompts\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Create positive and negative pairs\n",
    "        pos_prompt = self.label_prompts[label]\n",
    "        neg_prompt = self.label_prompts[1 - label]\n",
    "        \n",
    "        # Tokenize positive pair\n",
    "        pos_encoding = self.tokenizer(\n",
    "            text,\n",
    "            pos_prompt,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Tokenize negative pair\n",
    "        neg_encoding = self.tokenizer(\n",
    "            text,\n",
    "            neg_prompt, \n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'pos_input_ids': pos_encoding['input_ids'].squeeze(),\n",
    "            'pos_attention_mask': pos_encoding['attention_mask'].squeeze(),\n",
    "            'neg_input_ids': neg_encoding['input_ids'].squeeze(),\n",
    "            'neg_attention_mask': neg_encoding['attention_mask'].squeeze(),\n",
    "            'label': torch.tensor(1)  # Positive pair should entail\n",
    "        }\n",
    "\n",
    "class HateSpeechEntailmentModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = 'cardiffnlp/twitter-xlm-roberta-base-sentiment',\n",
    "        num_labels: int = 2\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Model class for entailment-style hate speech detection\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=num_labels\n",
    "        )\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        return outputs.logits\n",
    "\n",
    "# Add this to your imports\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    num_epochs: int = 5,\n",
    "    model_save_path: str = None\n",
    ") -> None:\n",
    "    \"\"\"Train model with validation monitoring\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_val_f1 = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Create progress bar for training\n",
    "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "        \n",
    "        for batch in train_pbar:\n",
    "            pos_input_ids = batch['pos_input_ids'].to(device)\n",
    "            pos_attention_mask = batch['pos_attention_mask'].to(device)\n",
    "            neg_input_ids = batch['neg_input_ids'].to(device)\n",
    "            neg_attention_mask = batch['neg_attention_mask'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass for both positive and negative pairs\n",
    "            pos_logits = model(pos_input_ids, pos_attention_mask)\n",
    "            neg_logits = model(neg_input_ids, neg_attention_mask)\n",
    "            \n",
    "            # Calculate loss\n",
    "            pos_labels = torch.ones(pos_logits.size(0), dtype=torch.long).to(device)\n",
    "            neg_labels = torch.zeros(neg_logits.size(0), dtype=torch.long).to(device)\n",
    "            \n",
    "            pos_loss = criterion(pos_logits, pos_labels)\n",
    "            neg_loss = criterion(neg_logits, neg_labels)\n",
    "            loss = pos_loss + neg_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        print(\"\\nRunning validation...\")\n",
    "        val_acc, val_f1 = evaluate(model, val_loader, device)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Average Loss: {avg_loss:.4f}\")\n",
    "        print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "        print(f\"Validation F1: {val_f1:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if model_save_path and val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Saved best model with F1: {val_f1:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual = []\n",
    "    \n",
    "    # Add progress bar for evaluation\n",
    "    eval_pbar = tqdm(dataloader, desc='Evaluating')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in eval_pbar:\n",
    "            pos_input_ids = batch['pos_input_ids'].to(device)\n",
    "            pos_attention_mask = batch['pos_attention_mask'].to(device)\n",
    "            \n",
    "            logits = model(pos_input_ids, pos_attention_mask)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            actual.extend(batch['label'].cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = sum(p == a for p, a in zip(predictions, actual)) / len(actual)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    tp = sum((p == 1 and a == 1) for p, a in zip(predictions, actual))\n",
    "    fp = sum((p == 1 and a == 0) for p, a in zip(predictions, actual))\n",
    "    fn = sum((p == 0 and a == 1) for p, a in zip(predictions, actual))\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ab011b7-3a7f-4559-bd03-63d529be7ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Initializing tokenizer and model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading data from data/latenthatred/latent_train.tsv\n",
      "Loaded 14273 examples\n",
      "Loading test data...\n",
      "Loading data from data/latenthatred/latent_test.tsv\n",
      "Loaded 4079 examples\n",
      "Creating dataloaders...\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 893/893 [05:35<00:00,  2.66it/s, loss=1.5136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 255/255 [00:16<00:00, 15.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n",
      "Average Loss: 1.1041\n",
      "Validation Accuracy: 0.8022\n",
      "Validation F1: 0.8902\n",
      "Saved best model with F1: 0.8902\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 893/893 [05:35<00:00,  2.66it/s, loss=0.9499]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 255/255 [00:16<00:00, 15.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/3\n",
      "Average Loss: 0.8393\n",
      "Validation Accuracy: 0.7499\n",
      "Validation F1: 0.8571\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 893/893 [05:35<00:00,  2.66it/s, loss=0.0129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 255/255 [00:16<00:00, 15.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/3\n",
      "Average Loss: 0.5427\n",
      "Validation Accuracy: 0.7566\n",
      "Validation F1: 0.8614\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluating best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 255/255 [00:16<00:00, 15.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Results:\n",
      "Accuracy: 0.8022\n",
      "F1 Score: 0.8902\n"
     ]
    }
   ],
   "source": [
    "#main for latent hatred dataset\n",
    "def main():\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Define paths\n",
    "    train_path = \"data/latenthatred/latent_train.tsv\"\n",
    "    test_path = \"data/latenthatred/latent_test.tsv\"\n",
    "    model_save_path = \"saved_models/best_model.pth\"\n",
    "    \n",
    "    # Create directory for saved models if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "    \n",
    "    # Define label prompts\n",
    "    label_prompts = {\n",
    "        0: \"this post contains normal words\",\n",
    "        1: \"this post contains hate speech\"\n",
    "    }\n",
    "    \n",
    "    # Initialize tokenizer and model\n",
    "    print(\"Initializing tokenizer and model...\")\n",
    "    model_name = 'bert-base-uncased'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = HateSpeechEntailmentModel(model_name).to(device)\n",
    "    \n",
    "    # Create datasets\n",
    "    print(\"Loading training data...\")\n",
    "    train_dataset = HateSpeechEntailmentDataset(\n",
    "        data_path=train_path,\n",
    "        tokenizer=tokenizer,\n",
    "        label_prompts=label_prompts\n",
    "    )\n",
    "    \n",
    "    print(\"Loading test data...\")\n",
    "    test_dataset = HateSpeechEntailmentDataset(\n",
    "        data_path=test_path,\n",
    "        tokenizer=tokenizer,\n",
    "        label_prompts=label_prompts\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders\n",
    "    print(\"Creating dataloaders...\")\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    # Train model\n",
    "    train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        optimizer,\n",
    "        device,\n",
    "        num_epochs=3,\n",
    "        model_save_path=model_save_path\n",
    "    )\n",
    "    \n",
    "    # Load best model and evaluate on test set\n",
    "    print(\"\\nEvaluating best model...\")\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    test_acc, test_f1 = evaluate(model, test_loader, device)\n",
    "    print(f\"\\nFinal Test Results:\")\n",
    "    print(f\"Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"F1 Score: {test_f1:.4f}\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeb690a-1593-44a8-bb53-8ebafc166e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21e7b3f8-c53d-497c-ad5e-bc8907c40ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List, Dict, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "class HateSpeechEntailmentDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str,\n",
    "        tokenizer: AutoTokenizer,\n",
    "        label_prompts: Dict[int, str],\n",
    "        label_strategy: str = 'hate_vs_nonhate',  # or 'hate_offensive_vs_normal'\n",
    "        max_length: int = 128\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Dataset class for entailment-style hate speech detection\n",
    "        \n",
    "        Args:\n",
    "            data_path: Path to TSV file with 'post' and 'class' columns\n",
    "            tokenizer: HuggingFace tokenizer\n",
    "            label_prompts: Dictionary mapping labels to prompt text\n",
    "            label_strategy: How to combine labels - either 'hate_vs_nonhate' or 'hate_offensive_vs_normal'\n",
    "            max_length: Maximum sequence length\n",
    "        \"\"\"\n",
    "        # Read TSV file\n",
    "        print(f\"Loading data from {data_path}\")\n",
    "        df = pd.read_csv(data_path, sep='\\t')\n",
    "        self.texts = df['post'].astype(str).tolist()\n",
    "        original_labels = df['label'].astype(int).tolist()\n",
    "        \n",
    "        # Convert 3-way labels to binary based on strategy\n",
    "        if label_strategy == 'hate_vs_nonhate':\n",
    "            # 2 (hate) -> 1, 1 (offensive) & 0 (normal) -> 0\n",
    "            self.labels = [1 if label == 2 else 0 for label in original_labels]\n",
    "        else:  # hate_offensive_vs_normal\n",
    "            # 2 (hate) & 1 (offensive) -> 1, 0 (normal) -> 0\n",
    "            self.labels = [0 if label == 0 else 1 for label in original_labels]\n",
    "            \n",
    "        print(f\"Loaded {len(self.texts)} examples\")\n",
    "        print(f\"Label distribution after conversion: {pd.Series(self.labels).value_counts()}\")\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.label_prompts = label_prompts\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Create positive and negative pairs\n",
    "        pos_prompt = self.label_prompts[label]\n",
    "        neg_prompt = self.label_prompts[1 - label]\n",
    "        \n",
    "        # Tokenize positive pair\n",
    "        pos_encoding = self.tokenizer(\n",
    "            text,\n",
    "            pos_prompt,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Tokenize negative pair\n",
    "        neg_encoding = self.tokenizer(\n",
    "            text,\n",
    "            neg_prompt, \n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'pos_input_ids': pos_encoding['input_ids'].squeeze(),\n",
    "            'pos_attention_mask': pos_encoding['attention_mask'].squeeze(),\n",
    "            'neg_input_ids': neg_encoding['input_ids'].squeeze(),\n",
    "            'neg_attention_mask': neg_encoding['attention_mask'].squeeze(),\n",
    "            'label': torch.tensor(1)  # Positive pair should entail\n",
    "        }\n",
    "\n",
    "class HateSpeechEntailmentModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = 'bert-base-uncased',\n",
    "        num_labels: int = 2\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Model class for entailment-style hate speech detection\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=num_labels\n",
    "        )\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        return outputs.logits\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    num_epochs: int = 3,\n",
    "    model_save_path: str = None\n",
    ") -> None:\n",
    "    \"\"\"Train model with validation monitoring\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_val_f1 = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Create progress bar for training\n",
    "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "        \n",
    "        for batch in train_pbar:\n",
    "            pos_input_ids = batch['pos_input_ids'].to(device)\n",
    "            pos_attention_mask = batch['pos_attention_mask'].to(device)\n",
    "            neg_input_ids = batch['neg_input_ids'].to(device)\n",
    "            neg_attention_mask = batch['neg_attention_mask'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass for both positive and negative pairs\n",
    "            pos_logits = model(pos_input_ids, pos_attention_mask)\n",
    "            neg_logits = model(neg_input_ids, neg_attention_mask)\n",
    "            \n",
    "            # Calculate loss\n",
    "            pos_labels = torch.ones(pos_logits.size(0), dtype=torch.long).to(device)\n",
    "            neg_labels = torch.zeros(neg_logits.size(0), dtype=torch.long).to(device)\n",
    "            \n",
    "            pos_loss = criterion(pos_logits, pos_labels)\n",
    "            neg_loss = criterion(neg_logits, neg_labels)\n",
    "            loss = pos_loss + neg_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        print(\"\\nRunning validation...\")\n",
    "        val_acc, val_f1 = evaluate(model, val_loader, device)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Average Loss: {avg_loss:.4f}\")\n",
    "        print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "        print(f\"Validation F1: {val_f1:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if model_save_path and val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Saved best model with F1: {val_f1:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual = []\n",
    "    \n",
    "    # Add progress bar for evaluation\n",
    "    eval_pbar = tqdm(dataloader, desc='Evaluating')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in eval_pbar:\n",
    "            pos_input_ids = batch['pos_input_ids'].to(device)\n",
    "            pos_attention_mask = batch['pos_attention_mask'].to(device)\n",
    "            \n",
    "            logits = model(pos_input_ids, pos_attention_mask)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            actual.extend(batch['label'].cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = sum(p == a for p, a in zip(predictions, actual)) / len(actual)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    tp = sum((p == 1 and a == 1) for p, a in zip(predictions, actual))\n",
    "    fp = sum((p == 1 and a == 0) for p, a in zip(predictions, actual))\n",
    "    fn = sum((p == 0 and a == 1) for p, a in zip(predictions, actual))\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbd9d123-0eee-41ff-b0dd-c4f4a59655b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Initializing tokenizer and model...\n",
      "Loading training data...\n",
      "Loading data from data/hatexplain/hx_train.tsv\n",
      "Loaded 15383 examples\n",
      "Label distribution after conversion: 1    9132\n",
      "0    6251\n",
      "dtype: int64\n",
      "Loading test data...\n",
      "Loading data from data/hatexplain/hx_test.tsv\n",
      "Loaded 1924 examples\n",
      "Label distribution after conversion: 1    1142\n",
      "0     782\n",
      "dtype: int64\n",
      "Creating dataloaders...\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 962/962 [06:01<00:00,  2.66it/s, loss=0.4863]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [00:08<00:00, 15.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n",
      "Average Loss: 1.0265\n",
      "Validation Accuracy: 0.7729\n",
      "Validation F1: 0.8719\n",
      "Saved best model with F1: 0.8719\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 962/962 [06:01<00:00,  2.66it/s, loss=1.2852]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [00:07<00:00, 15.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/3\n",
      "Average Loss: 0.7533\n",
      "Validation Accuracy: 0.7994\n",
      "Validation F1: 0.8885\n",
      "Saved best model with F1: 0.8885\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 962/962 [06:01<00:00,  2.66it/s, loss=0.0783]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [00:08<00:00, 15.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/3\n",
      "Average Loss: 0.4304\n",
      "Validation Accuracy: 0.7911\n",
      "Validation F1: 0.8833\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluating best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [00:08<00:00, 15.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Results:\n",
      "Accuracy: 0.7994\n",
      "F1 Score: 0.8885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Define paths\n",
    "    train_path = \"data/hatexplain/hx_train.tsv\"  # Update with your paths\n",
    "    test_path = \"data/hatexplain/hx_test.tsv\"\n",
    "    model_save_path = \"saved_models/best_model.pth\"\n",
    "    \n",
    "    # Create directory for saved models if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "    \n",
    "    # Choose your label strategy\n",
    "    label_strategy = 'hate_vs_nonhate'  # or 'hate_offensive_vs_normal'\n",
    "    \n",
    "    # Define label prompts based on strategy\n",
    "    if label_strategy == 'hate_vs_nonhate':\n",
    "        label_prompts = {\n",
    "            0: \"this post contains non-hateful content\",  # normal + offensive\n",
    "            1: \"this post contains hate speech\"  # hate\n",
    "        }\n",
    "    else:  # hate_offensive_vs_normal\n",
    "        label_prompts = {\n",
    "            0: \"this post contains normal content\",  # normal\n",
    "            1: \"this post contains harmful content\"  # hate + offensive\n",
    "        }\n",
    "    \n",
    "    # Initialize tokenizer and model\n",
    "    print(\"Initializing tokenizer and model...\")\n",
    "    model_name = 'bert-base-uncased'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = HateSpeechEntailmentModel(model_name).to(device)\n",
    "    \n",
    "    # Create datasets\n",
    "    print(\"Loading training data...\")\n",
    "    train_dataset = HateSpeechEntailmentDataset(\n",
    "        data_path=train_path,\n",
    "        tokenizer=tokenizer,\n",
    "        label_prompts=label_prompts,\n",
    "        label_strategy=label_strategy\n",
    "    )\n",
    "    \n",
    "    print(\"Loading test data...\")\n",
    "    test_dataset = HateSpeechEntailmentDataset(\n",
    "        data_path=test_path,\n",
    "        tokenizer=tokenizer,\n",
    "        label_prompts=label_prompts,\n",
    "        label_strategy=label_strategy\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders\n",
    "    print(\"Creating dataloaders...\")\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    # Train model\n",
    "    train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        optimizer,\n",
    "        device,\n",
    "        num_epochs=3,\n",
    "        model_save_path=model_save_path\n",
    "    )\n",
    "    \n",
    "    # Load best model and evaluate on test set\n",
    "    print(\"\\nEvaluating best model...\")\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    test_acc, test_f1 = evaluate(model, test_loader, device)\n",
    "    print(f\"\\nFinal Test Results:\")\n",
    "    print(f\"Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
