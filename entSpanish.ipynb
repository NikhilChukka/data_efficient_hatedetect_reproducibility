{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29ad3c2a-59a5-49eb-b622-2c6a8c98db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9336f7af-77f5-4502-9dc3-a9fac134185e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>such  racism goy  there is only       shared h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt and the color of facist fiction is white</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>girl  sure you can wait   must  coz your allah...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>who are their supporters black people or white...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you re wrong i m white and my kids are white</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14268</th>\n",
       "      <td>not only secure the border  but restrict all i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14269</th>\n",
       "      <td>the white genocide continues   white race now ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14270</th>\n",
       "      <td>so dan carlin is uninformed about the nordics ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14271</th>\n",
       "      <td>by western men  i mean white western men   don...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14272</th>\n",
       "      <td>goy is hebrew for nation   do you people fact ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14273 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    post  class\n",
       "0      such  racism goy  there is only       shared h...      1\n",
       "1            rt and the color of facist fiction is white      1\n",
       "2      girl  sure you can wait   must  coz your allah...      0\n",
       "3      who are their supporters black people or white...      0\n",
       "4           you re wrong i m white and my kids are white      0\n",
       "...                                                  ...    ...\n",
       "14268  not only secure the border  but restrict all i...      1\n",
       "14269  the white genocide continues   white race now ...      1\n",
       "14270  so dan carlin is uninformed about the nordics ...      1\n",
       "14271  by western men  i mean white western men   don...      0\n",
       "14272  goy is hebrew for nation   do you people fact ...      0\n",
       "\n",
       "[14273 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train1 = pd.read_csv(\"data/latenthatred/latent_train.tsv\", sep='\\t')\n",
    "df_test1 = pd.read_csv(\"data/latenthatred/latent_test.tsv\", sep='\\t')\n",
    "df_train1['class'].value_counts().sum()+ df_test1['class'].value_counts().sum()\n",
    "df_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0635c7b1-5d37-40ab-aa03-2fa451229399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "class HateSpeechEntailmentDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str,\n",
    "        tokenizer: AutoTokenizer,\n",
    "        label_prompts: Dict[int, str],\n",
    "        max_length: int = 128\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Dataset class for entailment-style hate speech detection\n",
    "        \n",
    "        Args:\n",
    "            data_path: Path to TSV file with 'post' and 'class' columns\n",
    "            tokenizer: HuggingFace tokenizer\n",
    "            label_prompts: Dictionary mapping labels to prompt text\n",
    "            max_length: Maximum sequence length\n",
    "        \"\"\"\n",
    "        # Read TSV file\n",
    "        print(f\"Loading data from {data_path}\")\n",
    "        df = pd.read_csv(data_path, sep='\\t')\n",
    "        self.texts = df['post'].astype(str).tolist()\n",
    "        self.labels = df['class'].astype(int).tolist()\n",
    "        print(f\"Loaded {len(self.texts)} examples\")\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.label_prompts = label_prompts\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Create positive and negative pairs\n",
    "        pos_prompt = self.label_prompts[label]\n",
    "        neg_prompt = self.label_prompts[1 - label]\n",
    "        \n",
    "        # Tokenize positive pair\n",
    "        pos_encoding = self.tokenizer(\n",
    "            text,\n",
    "            pos_prompt,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Tokenize negative pair\n",
    "        neg_encoding = self.tokenizer(\n",
    "            text,\n",
    "            neg_prompt, \n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'pos_input_ids': pos_encoding['input_ids'].squeeze(),\n",
    "            'pos_attention_mask': pos_encoding['attention_mask'].squeeze(),\n",
    "            'neg_input_ids': neg_encoding['input_ids'].squeeze(),\n",
    "            'neg_attention_mask': neg_encoding['attention_mask'].squeeze(),\n",
    "            'label': torch.tensor(1)  # Positive pair should entail\n",
    "        }\n",
    "\n",
    "class HateSpeechEntailmentModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = 'cardiffnlp/twitter-xlm-roberta-base-sentiment',\n",
    "        num_labels: int = 2\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Model class for entailment-style hate speech detection\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=num_labels\n",
    "        )\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        return outputs.logits\n",
    "\n",
    "# Add this to your imports\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    num_epochs: int = 5,\n",
    "    model_save_path: str = None\n",
    ") -> None:\n",
    "    \"\"\"Train model with validation monitoring\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_val_f1 = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Create progress bar for training\n",
    "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "        \n",
    "        for batch in train_pbar:\n",
    "            pos_input_ids = batch['pos_input_ids'].to(device)\n",
    "            pos_attention_mask = batch['pos_attention_mask'].to(device)\n",
    "            neg_input_ids = batch['neg_input_ids'].to(device)\n",
    "            neg_attention_mask = batch['neg_attention_mask'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass for both positive and negative pairs\n",
    "            pos_logits = model(pos_input_ids, pos_attention_mask)\n",
    "            neg_logits = model(neg_input_ids, neg_attention_mask)\n",
    "            \n",
    "            # Calculate loss\n",
    "            pos_labels = torch.ones(pos_logits.size(0), dtype=torch.long).to(device)\n",
    "            neg_labels = torch.zeros(neg_logits.size(0), dtype=torch.long).to(device)\n",
    "            \n",
    "            pos_loss = criterion(pos_logits, pos_labels)\n",
    "            neg_loss = criterion(neg_logits, neg_labels)\n",
    "            loss = pos_loss + neg_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        print(\"\\nRunning validation...\")\n",
    "        val_acc, val_f1 = evaluate(model, val_loader, device)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Average Loss: {avg_loss:.4f}\")\n",
    "        print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "        print(f\"Validation F1: {val_f1:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if model_save_path and val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Saved best model with F1: {val_f1:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual = []\n",
    "    \n",
    "    # Add progress bar for evaluation\n",
    "    eval_pbar = tqdm(dataloader, desc='Evaluating')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in eval_pbar:\n",
    "            pos_input_ids = batch['pos_input_ids'].to(device)\n",
    "            pos_attention_mask = batch['pos_attention_mask'].to(device)\n",
    "            \n",
    "            logits = model(pos_input_ids, pos_attention_mask)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            actual.extend(batch['label'].cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = sum(p == a for p, a in zip(predictions, actual)) / len(actual)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    tp = sum((p == 1 and a == 1) for p, a in zip(predictions, actual))\n",
    "    fp = sum((p == 1 and a == 0) for p, a in zip(predictions, actual))\n",
    "    fn = sum((p == 0 and a == 1) for p, a in zip(predictions, actual))\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ab011b7-3a7f-4559-bd03-63d529be7ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main for latent hatred dataset\n",
    "def main():\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Define paths\n",
    "    train_path = \"data/latenthatred/latent_train.tsv\"\n",
    "    test_path = \"data/latenthatred/latent_test.tsv\"\n",
    "    model_save_path = \"saved_models/best_model.pth\"\n",
    "    \n",
    "    # Create directory for saved models if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "    \n",
    "    # Define label prompts\n",
    "    label_prompts = {\n",
    "        0: \"this post contains normal words\",\n",
    "        1: \"this post contains hate speech\"\n",
    "    }\n",
    "    \n",
    "    # Initialize tokenizer and model\n",
    "    print(\"Initializing tokenizer and model...\")\n",
    "    model_name = 'bert-base-uncased'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = HateSpeechEntailmentModel(model_name).to(device)\n",
    "    \n",
    "    # Create datasets\n",
    "    print(\"Loading training data...\")\n",
    "    train_dataset = HateSpeechEntailmentDataset(\n",
    "        data_path=train_path,\n",
    "        tokenizer=tokenizer,\n",
    "        label_prompts=label_prompts\n",
    "    )\n",
    "    \n",
    "    print(\"Loading test data...\")\n",
    "    test_dataset = HateSpeechEntailmentDataset(\n",
    "        data_path=test_path,\n",
    "        tokenizer=tokenizer,\n",
    "        label_prompts=label_prompts\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders\n",
    "    print(\"Creating dataloaders...\")\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    # Train model\n",
    "    train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        optimizer,\n",
    "        device,\n",
    "        num_epochs=3,\n",
    "        model_save_path=model_save_path\n",
    "    )\n",
    "    \n",
    "    # Load best model and evaluate on test set\n",
    "    print(\"\\nEvaluating best model...\")\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    test_acc, test_f1 = evaluate(model, test_loader, device)\n",
    "    print(f\"\\nFinal Test Results:\")\n",
    "    print(f\"Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"F1 Score: {test_f1:.4f}\")\n",
    "if __name__ == \"__main__\":\n",
    "    pass\n",
    "    # main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfeb690a-1593-44a8-bb53-8ebafc166e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Initializing tokenizer and model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31cbade2ef748bd866d5b7d2699b937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cb78735c6f0428d912106a158c3c8e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b09d5f657e4681869e320005c31c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d00c932a3dc484e9967d5f8a809cf46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853af1252fa241cea54038f77a124396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading data from data/multilingual/train_spanish.tsv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages/pandas/core/indexes/base.py:3361\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3362\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages/pandas/_libs/index.pyx:76\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages/pandas/_libs/index.pyx:108\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'class'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 77>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_f1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Create datasets\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading training data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mHateSpeechEntailmentDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_prompts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel_prompts\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading test data...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m HateSpeechEntailmentDataset(\n\u001b[1;32m     37\u001b[0m     data_path\u001b[38;5;241m=\u001b[39mtest_path,\n\u001b[1;32m     38\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m     39\u001b[0m     label_prompts\u001b[38;5;241m=\u001b[39mlabel_prompts\n\u001b[1;32m     40\u001b[0m )\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mHateSpeechEntailmentDataset.__init__\u001b[0;34m(self, data_path, tokenizer, label_prompts, max_length)\u001b[0m\n\u001b[1;32m     28\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(data_path, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtexts \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtexts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m tokenizer\n",
      "File \u001b[0;32m/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages/pandas/core/frame.py:3458\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3458\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3460\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/sw/spack/apps/linux-rhel8-x86_64_v2/gcc-10.3.0/python-3.9.9-jh/lib/python3.9/site-packages/pandas/core/indexes/base.py:3363\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3362\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3363\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_scalar(key) \u001b[38;5;129;01mand\u001b[39;00m isna(key) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhasnans:\n\u001b[1;32m   3366\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'class'"
     ]
    }
   ],
   "source": [
    "#main for latent hatred dataset\n",
    "def main():\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Define paths\n",
    "    train_path = \"data/multilingual/train_spanish.tsv\"\n",
    "    test_path = \"data/multilingual/test_spanish.tsv\"\n",
    "    model_save_path = \"saved_models/best_model.pth\"\n",
    "    \n",
    "    # Create directory for saved models if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "    \n",
    "    # Define label prompts\n",
    "    label_prompts = {\n",
    "        0: \"this post contains normal words\",\n",
    "        1: \"this post contains hate speech\"\n",
    "    }\n",
    "    \n",
    "    # Initialize tokenizer and model\n",
    "    print(\"Initializing tokenizer and model...\")\n",
    "    model_name = 'xlm-roberta-base'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = HateSpeechEntailmentModel(model_name).to(device)\n",
    "    \n",
    "    # Create datasets\n",
    "    print(\"Loading training data...\")\n",
    "    train_dataset = HateSpeechEntailmentDataset(\n",
    "        data_path=train_path,\n",
    "        tokenizer=tokenizer,\n",
    "        label_prompts=label_prompts\n",
    "    )\n",
    "    \n",
    "    print(\"Loading test data...\")\n",
    "    test_dataset = HateSpeechEntailmentDataset(\n",
    "        data_path=test_path,\n",
    "        tokenizer=tokenizer,\n",
    "        label_prompts=label_prompts\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders\n",
    "    print(\"Creating dataloaders...\")\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    # Train model\n",
    "    train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        optimizer,\n",
    "        device,\n",
    "        num_epochs=3,\n",
    "        model_save_path=model_save_path\n",
    "    )\n",
    "    \n",
    "    # Load best model and evaluate on test set\n",
    "    print(\"\\nEvaluating best model...\")\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    test_acc, test_f1 = evaluate(model, test_loader, device)\n",
    "    print(f\"\\nFinal Test Results:\")\n",
    "    print(f\"Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"F1 Score: {test_f1:.4f}\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21e7b3f8-c53d-497c-ad5e-bc8907c40ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Initializing tokenizer and model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Loading data from data/hatexplain/hx_train.tsv\n",
      "Loaded 15383 examples\n",
      "Label distribution after conversion: 0    10635\n",
      "1     4748\n",
      "dtype: int64\n",
      "Loading test data...\n",
      "Loading data from data/hatexplain/hx_test.tsv\n",
      "Loaded 1924 examples\n",
      "Label distribution after conversion: 0    1330\n",
      "1     594\n",
      "dtype: int64\n",
      "Creating dataloaders...\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 481/481 [05:43<00:00,  1.40it/s, loss=0.5112]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:07<00:00,  7.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n",
      "Average Loss: 0.8008\n",
      "Validation Accuracy: 0.8643\n",
      "Validation F1: 0.9272\n",
      "Saved best model with F1: 0.9272\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 481/481 [05:44<00:00,  1.40it/s, loss=0.6132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:07<00:00,  7.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/5\n",
      "Average Loss: 0.5800\n",
      "Validation Accuracy: 0.8488\n",
      "Validation F1: 0.9182\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 481/481 [05:44<00:00,  1.40it/s, loss=0.3374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:07<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/5\n",
      "Average Loss: 0.3827\n",
      "Validation Accuracy: 0.8467\n",
      "Validation F1: 0.9170\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 481/481 [05:43<00:00,  1.40it/s, loss=0.2614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:07<00:00,  7.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/5\n",
      "Average Loss: 0.1989\n",
      "Validation Accuracy: 0.8368\n",
      "Validation F1: 0.9111\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [Train]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 481/481 [05:43<00:00,  1.40it/s, loss=0.1262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:07<00:00,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/5\n",
      "Average Loss: 0.0997\n",
      "Validation Accuracy: 0.8243\n",
      "Validation F1: 0.9037\n",
      "--------------------------------------------------\n",
      "\n",
      "Evaluating best model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61/61 [00:07<00:00,  7.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Results:\n",
      "Accuracy: 0.8643\n",
      "F1 Score: 0.9272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List, Dict, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "class HateSpeechEntailmentDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str,\n",
    "        tokenizer: AutoTokenizer,\n",
    "        label_prompts: Dict[int, str],\n",
    "        label_strategy: str = 'hate_vs_nonhate',  # or 'hate_offensive_vs_normal'\n",
    "        max_length: int = 128\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Dataset class for entailment-style hate speech detection\n",
    "        \n",
    "        Args:\n",
    "            data_path: Path to TSV file with 'post' and 'class' columns\n",
    "            tokenizer: HuggingFace tokenizer\n",
    "            label_prompts: Dictionary mapping labels to prompt text\n",
    "            label_strategy: How to combine labels - either 'hate_vs_nonhate' or 'hate_offensive_vs_normal'\n",
    "            max_length: Maximum sequence length\n",
    "        \"\"\"\n",
    "        # Read TSV file\n",
    "        print(f\"Loading data from {data_path}\")\n",
    "        df = pd.read_csv(data_path, sep='\\t')\n",
    "        self.texts = df['post'].astype(str).tolist()\n",
    "        original_labels = df['label'].astype(int).tolist()\n",
    "        \n",
    "        # Convert 3-way labels to binary based on strategy\n",
    "        if label_strategy == 'hate_vs_nonhate':\n",
    "            # 2 (hate) -> 1, 1 (offensive) & 0 (normal) -> 0\n",
    "            self.labels = [1 if label == 2 else 0 for label in original_labels]\n",
    "        else:  # hate_offensive_vs_normal\n",
    "            # 2 (hate) & 1 (offensive) -> 1, 0 (normal) -> 0\n",
    "            self.labels = [0 if label == 0 else 1 for label in original_labels]\n",
    "            \n",
    "        print(f\"Loaded {len(self.texts)} examples\")\n",
    "        print(f\"Label distribution after conversion: {pd.Series(self.labels).value_counts()}\")\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.label_prompts = label_prompts\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Create positive and negative pairs\n",
    "        pos_prompt = self.label_prompts[label]\n",
    "        neg_prompt = self.label_prompts[1 - label]\n",
    "        \n",
    "        # Tokenize positive pair\n",
    "        pos_encoding = self.tokenizer(\n",
    "            text,\n",
    "            pos_prompt,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Tokenize negative pair\n",
    "        neg_encoding = self.tokenizer(\n",
    "            text,\n",
    "            neg_prompt, \n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'pos_input_ids': pos_encoding['input_ids'].squeeze(),\n",
    "            'pos_attention_mask': pos_encoding['attention_mask'].squeeze(),\n",
    "            'neg_input_ids': neg_encoding['input_ids'].squeeze(),\n",
    "            'neg_attention_mask': neg_encoding['attention_mask'].squeeze(),\n",
    "            'label': torch.tensor(1)  # Positive pair should entail\n",
    "        }\n",
    "\n",
    "class HateSpeechEntailmentModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str = 'bert-base-uncased',\n",
    "        num_labels: int = 2\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Model class for entailment-style hate speech detection\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels=num_labels\n",
    "        )\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        outputs = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        return outputs.logits\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: torch.device,\n",
    "    num_epochs: int = 3,\n",
    "    model_save_path: str = None\n",
    ") -> None:\n",
    "    \"\"\"Train model with validation monitoring\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_val_f1 = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        # Create progress bar for training\n",
    "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "        \n",
    "        for batch in train_pbar:\n",
    "            pos_input_ids = batch['pos_input_ids'].to(device)\n",
    "            pos_attention_mask = batch['pos_attention_mask'].to(device)\n",
    "            neg_input_ids = batch['neg_input_ids'].to(device)\n",
    "            neg_attention_mask = batch['neg_attention_mask'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass for both positive and negative pairs\n",
    "            pos_logits = model(pos_input_ids, pos_attention_mask)\n",
    "            neg_logits = model(neg_input_ids, neg_attention_mask)\n",
    "            \n",
    "            # Calculate loss\n",
    "            pos_labels = torch.ones(pos_logits.size(0), dtype=torch.long).to(device)\n",
    "            neg_labels = torch.zeros(neg_logits.size(0), dtype=torch.long).to(device)\n",
    "            \n",
    "            pos_loss = criterion(pos_logits, pos_labels)\n",
    "            neg_loss = criterion(neg_logits, neg_labels)\n",
    "            loss = pos_loss + neg_loss\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            train_pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        # Validation\n",
    "        print(\"\\nRunning validation...\")\n",
    "        val_acc, val_f1 = evaluate(model, val_loader, device)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Average Loss: {avg_loss:.4f}\")\n",
    "        print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
    "        print(f\"Validation F1: {val_f1:.4f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if model_save_path and val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Saved best model with F1: {val_f1:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "def evaluate(\n",
    "    model: nn.Module,\n",
    "    dataloader: DataLoader,\n",
    "    device: torch.device\n",
    ") -> Tuple[float, float]:\n",
    "    \"\"\"Evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual = []\n",
    "    \n",
    "    # Add progress bar for evaluation\n",
    "    eval_pbar = tqdm(dataloader, desc='Evaluating')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in eval_pbar:\n",
    "            pos_input_ids = batch['pos_input_ids'].to(device)\n",
    "            pos_attention_mask = batch['pos_attention_mask'].to(device)\n",
    "            \n",
    "            logits = model(pos_input_ids, pos_attention_mask)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            actual.extend(batch['label'].cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = sum(p == a for p, a in zip(predictions, actual)) / len(actual)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    tp = sum((p == 1 and a == 1) for p, a in zip(predictions, actual))\n",
    "    fp = sum((p == 1 and a == 0) for p, a in zip(predictions, actual))\n",
    "    fn = sum((p == 0 and a == 1) for p, a in zip(predictions, actual))\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return accuracy, f1\n",
    "\n",
    "def main():\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Define paths\n",
    "    train_path = \"data/hatexplain/hx_train.tsv\"  # Update with your paths\n",
    "    test_path = \"data/hatexplain/hx_test.tsv\"\n",
    "    model_save_path = \"saved_models/best_model.pth\"\n",
    "    \n",
    "    # Create directory for saved models if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "    \n",
    "    # Choose your label strategy\n",
    "    label_strategy = 'hate_vs_nonhate'  # or 'hate_offensive_vs_normal'\n",
    "    \n",
    "    # Define label prompts based on strategy\n",
    "    if label_strategy == 'hate_vs_nonhate':\n",
    "        label_prompts = {\n",
    "            0: \"this post contains non-hateful content\",  # normal + offensive\n",
    "            1: \"this post contains hate speech\"  # hate\n",
    "        }\n",
    "    else:  # hate_offensive_vs_normal\n",
    "        label_prompts = {\n",
    "            0: \"this post contains normal content\",  # normal\n",
    "            1: \"this post contains harmful content\"  # hate + offensive\n",
    "        }\n",
    "    \n",
    "    # Initialize tokenizer and model\n",
    "    print(\"Initializing tokenizer and model...\")\n",
    "    model_name = 'bert-base-uncased'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = HateSpeechEntailmentModel(model_name).to(device)\n",
    "    \n",
    "    # Create datasets\n",
    "    print(\"Loading training data...\")\n",
    "    train_dataset = HateSpeechEntailmentDataset(\n",
    "        data_path=train_path,\n",
    "        tokenizer=tokenizer,\n",
    "        label_prompts=label_prompts,\n",
    "        label_strategy=label_strategy\n",
    "    )\n",
    "    \n",
    "    print(\"Loading test data...\")\n",
    "    test_dataset = HateSpeechEntailmentDataset(\n",
    "        data_path=test_path,\n",
    "        tokenizer=tokenizer,\n",
    "        label_prompts=label_prompts,\n",
    "        label_strategy=label_strategy\n",
    "    )\n",
    "    \n",
    "    # Create dataloaders\n",
    "    print(\"Creating dataloaders...\")\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=True\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-5)\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    # Train model\n",
    "    train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        test_loader,\n",
    "        optimizer,\n",
    "        device,\n",
    "        num_epochs=5,\n",
    "        model_save_path=model_save_path\n",
    "    )\n",
    "    \n",
    "    # Load best model and evaluate on test set\n",
    "    print(\"\\nEvaluating best model...\")\n",
    "    model.load_state_dict(torch.load(model_save_path))\n",
    "    test_acc, test_f1 = evaluate(model, test_loader, device)\n",
    "    print(f\"\\nFinal Test Results:\")\n",
    "    print(f\"Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
