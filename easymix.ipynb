{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39ea1973-e66a-44d8-843b-d67a364157e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad239020-27bb-4886-8c61-e1908e57e506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch import optim\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from transformers import BertTokenizer, AutoTokenizer\n",
    "from transformers import BertModel, AutoModel, AutoModelForSequenceClassification\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "use_cuda = True if torch.cuda.is_available() else False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# use_cuda=False\n",
    "# device='cpu'\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "base_model = 'twitter-xlm-roberta-base-sentiment'\n",
    "model_list = ['bert-base-uncased', 'bert-base-multilingual-uncased', 'google/muril-base-cased', 'xlm-roberta-base',\n",
    "              'ai4bharat/indic-bert','cardiffnlp/twitter-xlm-roberta-base','cardiffnlp/twitter-xlm-roberta-base-sentiment',\n",
    "              'cardiffnlp/twitter-roberta-base', 'cardiffnlp/twitter-roberta-base-sentiment',\n",
    "              'cardiffnlp/twitter-roberta-base-hate', 'roberta-base']\n",
    "model_path = '/mnt/saved_models/'\n",
    "results_path = '/mnt/saved_results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0da5f88b-0f84-4c67-8eba-8a90b0095c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'portuguese'\n",
    "model_choice = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99050998-e6fc-4236-b022-6b337c2aad28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writer = SummaryWriter(log_dir=\"/home/jupyter/tboard/\" + base_model + \"_\" + lang)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f2fcfaf-e554-4934-9494-4e162e6d8fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_list[model_choice])\n",
    "\n",
    "MAX_SEQ_LEN = 128\n",
    "\n",
    "label_idx = 1\n",
    "text_idx = 0\n",
    "\n",
    "class HateData(Dataset):\n",
    "    def __init__(self, data_path, split='train', lang='bengali', aug_prob=0.2, flip_prob=0.5):\n",
    "        self.split = split\n",
    "        # self.data = pd.read_parquet(data_path + lang + \"_\" + split + \".parquet\", engine='fastparquet')\n",
    "        # self.data = pd.read_csv(data_path, sep=',')\n",
    "        # self.data = pd.read_csv(data_path + lang + \"_\" + split + \".tsv\", sep='\\t')\n",
    "        self.data = pd.read_csv(data_path + split + \"_\" + lang + \".tsv\", sep='\\t', lineterminator='\\n')\n",
    "        \n",
    "        if self.split == 'train':\n",
    "            self.label2data = {0:[], 1:[], 2:[]}\n",
    "            # self.data = self.data[self.data['language'] == lang]\n",
    "            \n",
    "            for i in tqdm(range(len(self.data))):\n",
    "                row = self.data.iloc[i]\n",
    "                self.label2data[row[label_idx]].append(row[text_idx])\n",
    "            self.aug_prob = aug_prob\n",
    "            self.flip_prob = flip_prob\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "\n",
    "        data = self.data.iloc[index]\n",
    "\n",
    "        labels = data[label_idx]\n",
    "        text = data[text_idx]\n",
    "        inputs = tokenizer(text, padding='max_length', truncation=True, max_length=MAX_SEQ_LEN)\n",
    "        # print(inputs)\n",
    "        input_ids = inputs['input_ids']\n",
    "        token_type_ids = np.zeros(MAX_SEQ_LEN)#inputs['token_type_ids']#\n",
    "        attn_mask = inputs['attention_mask']\n",
    "        \n",
    "        aug_text = text  \n",
    "        labels_aug = labels\n",
    "        \n",
    "        if self.split == 'train' and labels == 1:\n",
    "            if np.random.uniform() < self.aug_prob:\n",
    "                aug_text = np.random.choice(self.label2data[0])\n",
    "         \n",
    "                if np.random.uniform() < self.flip_prob:\n",
    "                    aug_text = aug_text + \" [SEP] \" + text\n",
    "                else:\n",
    "                    aug_text = text + \" [SEP] \" + aug_text \n",
    "            labels_aug = 1\n",
    "      \n",
    "        inputs_aug = tokenizer(aug_text, padding='max_length', truncation=True, max_length=MAX_SEQ_LEN)\n",
    "        # print(inputs)\n",
    "        input_ids_aug = inputs_aug['input_ids']\n",
    "        token_type_ids_aug = np.zeros(MAX_SEQ_LEN)#inputs_aug['token_type_ids']#\n",
    "        attn_mask_aug = inputs_aug['attention_mask']\n",
    "\n",
    "        input_ids = torch.tensor(np.vstack([input_ids, input_ids_aug]), dtype=torch.long).view(2, MAX_SEQ_LEN)\n",
    "        token_type_ids = torch.tensor(np.vstack([token_type_ids, token_type_ids_aug]), dtype=torch.long).view(2, MAX_SEQ_LEN)\n",
    "        attn_mask = torch.tensor(np.vstack([attn_mask, attn_mask_aug]), dtype=torch.long).view(2, MAX_SEQ_LEN)\n",
    "        labels = torch.tensor(np.vstack([labels, labels_aug]), dtype=torch.long).view(2)\n",
    "\n",
    "\n",
    "        return input_ids, attn_mask, token_type_ids, labels\n",
    "\n",
    "\n",
    "# train_data = HateData(data_path=\"/home/jupyter/data/implicit-hate-corpus/\", lang='latent')\n",
    "# dataload = DataLoader(train_data, batch_size=4)\n",
    "\n",
    "# for i in (dataload):\n",
    "#     print(i[0].shape)\n",
    "#     print(i[1].shape)\n",
    "#     print(i[2].shape)\n",
    "#     print(i[3].shape)\n",
    "#     break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf8548d8-c91b-4ccf-a518-0635f05579ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "\n",
    "        H1, H2, num_class = 768, 128, 2\n",
    "        self.bert = AutoModel.from_pretrained(model_list[model_choice])\n",
    "        \n",
    "        # for param in self.bert.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "        self.clf = nn.Sequential(\n",
    "            nn.Linear(H1, H2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(H2, H2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(H2, num_class)\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self, input_ids, attn_mask, token_type_ids):  \n",
    "        outputs = self.bert(input_ids, attn_mask)#, token_type_ids)\n",
    "        cls_emb = outputs.pooler_output # (batch, 768)\n",
    "        logits = self.clf(cls_emb) # (batch, num_class)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9bbaa46-9b44-49af-bb49-124e9af439ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a4d0548-5e3d-4279-ad0b-1d9d566d3f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_ids, attn_mask, token_type_ids, label, model, model_opt, scdl):\n",
    "\n",
    "    model_opt.zero_grad()\n",
    "\n",
    "    batch_size = input_ids.shape[0]\n",
    "    seq_len = input_ids.shape[1]\n",
    "\n",
    "    loss = 0.0\n",
    "\n",
    "    if use_cuda:\n",
    "        input_ids = input_ids.to(device)\n",
    "        attn_mask = attn_mask.to(device)\n",
    "        token_type_ids = token_type_ids.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "    # label = label.flatten()\n",
    "    \n",
    "    logits = model(input_ids[:,0,:], attn_mask[:,0,:], token_type_ids[:,0,:])\n",
    "    logits_aug = model(input_ids[:,1,:], attn_mask[:,1,:], token_type_ids[:,1,:])\n",
    "\n",
    "    loss = loss_fn(logits, label[:,0]) + loss_fn(logits_aug, label[:,1])\n",
    "\n",
    "    # if torch.isnan(loss):\n",
    "    #     pass\n",
    "    # else:\n",
    "    loss.backward()\n",
    "    # torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # clip gradients to prevent exploding\n",
    "    model_opt.step()\n",
    "    scdl.step()\n",
    "    # print(loss)\n",
    "    return float(loss.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ad57855-ee8b-448e-9c03-0049d81db476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(input_ids, attn_mask, token_type_ids, label, model, mode='train'):\n",
    "   \n",
    "    batch_size = input_ids.shape[0]\n",
    "    seq_len = input_ids.shape[1]\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if use_cuda:\n",
    "            input_ids = input_ids.to(device)\n",
    "            attn_mask = attn_mask.to(device)\n",
    "            token_type_ids = token_type_ids.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "        # label = label.flatten()\n",
    "        \n",
    "        logits = model(input_ids[:,0,:], attn_mask[:,0,:], token_type_ids[:,0,:])\n",
    "        loss = loss_fn(logits, label[:,0])\n",
    "        \n",
    "        if mode == 'train':\n",
    "            return float(loss.item())\n",
    "        \n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "        # acc = (preds == label).cpu().numpy().mean() * 100\n",
    "\n",
    "        return float(loss.item()), preds.cpu().numpy()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1958148f-3d6f-4574-b799-9edf2a791f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"/home/jupyter/multilingual/test_data/test_portuguese.tsv\", sep='\\t', lineterminator='\\n')\n",
    "gt_labels = np.array(df_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7016425-389c-45d9-8cb6-a11c73fcdb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gt_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dabe9a9f-e8a6-4712-bf00-ae5d75d16bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(model, epochs, train_loader, test_loader, learning_rate=3e-5, log_step=168, valid_step=168, mode='train'):\n",
    "\n",
    "    model_opt = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
    "    num_train_steps = (len(train_loader)*epochs) \n",
    "    scdl = get_linear_schedule_with_warmup(model_opt, num_warmup_steps=int(0.1*num_train_steps), num_training_steps=num_train_steps)\n",
    "\n",
    "    print(\"Initialised optimizer and lr scheduler\")\n",
    "\n",
    "    # valid_best_loss = [] \n",
    "    best_acc = 0.0 \n",
    "    tot = len(train_data) // train_loader.batch_size\n",
    "    tot_val = len(val_data) // test_loader.batch_size\n",
    "    plot_steps = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss_total = 0.0\n",
    "        train_step = 0\n",
    "        # Training\n",
    "        \n",
    "        model.train()        \n",
    "        for entry in tqdm(train_loader, total=tot, position=0, leave=True):\n",
    "            loss = train(entry[0], entry[1], entry[2], entry[3], model, model_opt, scdl)\n",
    "            plot_steps += 1\n",
    "            train_step += 1\n",
    "            # if not math.isnan(loss) :      \n",
    "            train_loss_total = train_loss_total + loss\n",
    "            \n",
    "            train_loss = train_loss_total / train_step\n",
    "            \n",
    "            if plot_steps % log_step == 0:\n",
    "                writer.add_scalar(\"Train Loss\", train_loss, plot_steps)\n",
    "            \n",
    "            if (plot_steps % valid_step == 0) or (plot_steps >= num_train_steps - 1):\n",
    "                model.eval()\n",
    "                test_pred = []\n",
    "\n",
    "                for entry in tqdm(test_loader, total=tot_val, position=0, leave=True):\n",
    "                    loss_v, pred_v = evaluate(entry[0], entry[1], entry[2], entry[3], model, mode='test')\n",
    "                    # if not math.isnan(loss) :      \n",
    "                    test_pred.extend([pd for pd in pred_v])\n",
    "\n",
    "                # val_acc = (test_pred == gt_labels).mean().item()\n",
    "                val_acc = f1_score(gt_labels, test_pred, average='macro')\n",
    "                print(\"Validation F1: \" + str(val_acc))\n",
    "                writer.add_scalar(\"Val F1\", val_acc, plot_steps)\n",
    "\n",
    "\n",
    "                #   Save best model\n",
    "                # state = {\n",
    "                #         'epoch': epoch,\n",
    "                #         'state_dict': model.state_dict(),\n",
    "                #         'optimizer': model_opt.state_dict(),\n",
    "                #         'loss': train_loss,\n",
    "                #         'scheduler': scdl.state_dict(),\n",
    "                # }\n",
    "\n",
    "\n",
    "                if val_acc > best_acc:\n",
    "                    torch.save(model.state_dict(), model_path + \"model_\" + base_model + \"_\" + lang + \"_easymix_mono_redo\" + \".pth\") \n",
    "                    print(\"Model saved for step: \" + str(plot_steps))\n",
    "                    best_acc = val_acc         \n",
    "\n",
    "                model.train()\n",
    "            writer.flush()\n",
    "                \n",
    "\n",
    "        print('epoch: '+str(epoch))\n",
    "        print('total loss: '+str(train_loss_total/tot))\n",
    "\n",
    "        # wr_train = open(results_path + \"train_loss_\" + base_model + \".txt\", \"a\")\n",
    "        # wr_train.write(\"epoch \" + str(epoch) + \": \" + str(train_loss_total/tot) + \"\\n\")\n",
    "        # wr_train.close()\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed2a7f13-faa6-4e64-857e-4b47eea70546",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5386/5386 [00:00<00:00, 12640.44it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = HateData(data_path=\"/home/jupyter/multilingual/train_data/\", split='train', lang=lang)\n",
    "val_data = HateData(data_path=\"/home/jupyter/multilingual/test_data/\", split='test', lang=lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0410c5b-dd55-4523-9ce0-247538308727",
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 16\n",
    "# weights = [1.0]*15383\n",
    "# weights.extend([0.5]*(len(train_data) - 15383))\n",
    "# sampler = WeightedRandomSampler(weights, num_samples=20000)\n",
    "\n",
    "dataload = DataLoader(train_data, batch_size=BS, shuffle=True)\n",
    "dataload_val = DataLoader(val_data, batch_size=BS, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "552520b0-9b62-440a-b8db-5e8468514759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(train_data)/16)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47dbc8a3-d7fc-4ab9-8b82-ea95cac708d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-xlm-roberta-base-sentiment were not used when initializing XLMRobertaModel: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base-sentiment and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# model = Classifier()\n",
    "# model = model.float()\n",
    "# # model = nn.DataParallel(model)#, device_ids = [2, 3]\n",
    "# model = model.to(device)\n",
    "model = Classifier()\n",
    "# model = nn.DataParallel(model)\n",
    "model.load_state_dict(torch.load(\"/mnt/saved_models/model_twitter-xlm-roberta-base-sentiment_multilingual_redo.pth\", map_location=device))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62b6aaed-5664-4b8f-b2b5-717104c11c16",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised optimizer and lr scheduler\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 20.97it/s]                        s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.718214032600992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 168/336 [02:19<11:46,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for step: 168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 21.05it/s]                        s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.7236514018123215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 336/336 [04:37<00:00,  4.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for step: 336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "337it [04:38,  1.21it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "total loss: 0.8375466388339797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 20.79it/s]                        s]\n",
      " 50%|████▉     | 167/336 [02:07<02:53,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.7106514356282803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 21.10it/s]                        s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.7260393328354494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 335/336 [04:26<00:04,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for step: 672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "337it [04:27,  1.26it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "total loss: 0.6285899799938003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 21.24it/s]                        s]\n",
      " 49%|████▉     | 166/336 [02:06<02:50,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.7051156880065708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18it [00:00, 21.37it/s]                        s]\n",
      " 99%|█████████▉| 334/336 [04:14<00:02,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1: 0.6734511027819672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "337it [04:16,  1.32it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2\n",
      "total loss: 0.32165907951448824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 52/336 [00:39<03:34,  1.33it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3697/253192091.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataload_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_3697/1351368711.py\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(model, epochs, train_loader, test_loader, learning_rate, log_step, valid_step, mode)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mplot_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mtrain_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3697/3624887270.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_ids, attn_mask, token_type_ids, label, model, model_opt, scdl)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# label = label.flatten()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mlogits_aug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_3697/1170366284.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attn_mask, token_type_ids)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, token_type_ids)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mcls_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler_output\u001b[0m \u001b[0;31m# (batch, 768)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_emb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (batch, num_class)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         )\n\u001b[1;32m    862\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    531\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m                 )\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         )\n\u001b[1;32m    419\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         )\n\u001b[1;32m    348\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_probs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/traceback.py\u001b[0m in \u001b[0;36mformat_stack\u001b[0;34m(f, limit)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mformat_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;34m\"\"\"Shorthand for 'format_list(extract_stack(f, limit))'.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainIters(model, 5, dataload, dataload_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d8c81c-7688-4c1d-94b7-e190984e717e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad6a35c-7ba5-45c6-a025-ab4b4575ab29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2ed3ec-1294-473f-8f98-23a6f816a28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cfb1fe-2c3d-4f0d-b21d-21ce57faa3e5",
   "metadata": {},
   "source": [
    "######################## TESTING ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19bbbce2-7488-4118-ba55-8a88b7d67a03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-xlm-roberta-base-sentiment were not used when initializing XLMRobertaModel: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base-sentiment and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Classifier()\n",
    "# model = nn.DataParallel(model)\n",
    "model.load_state_dict(torch.load(\"/mnt/saved_models/model_twitter-roberta-base-sentiment_\" + lang + \"_easymix\" + \"_redo.pth\", map_location=device))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a2dcc3d-6bed-46b3-af1f-724e1cc33970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spanish'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang #= 'hindi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bb602bc-5bc9-4da0-a92a-3798f2b91dca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_data = HateData(data_path=\"/home/jupyter/data/test_data/bq_test_\" + lang + \"_process_10k.csv\")\n",
    "test_data = HateData(data_path=\"/home/jupyter/multilingual/test_data/\", split='test', lang=lang)\n",
    "test_loader = DataLoader(test_data, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d3a48d8-f73b-41ff-98e9-4ba1734cb2cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1600/1600 [00:35<00:00, 45.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  0.4558552019682247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = []\n",
    "test_pred = []\n",
    "\n",
    "# wr = open(results_path + \"test_prediction_\" + base_model + \"_\" + lang + \"_process_10k.txt\", \"w\")     \n",
    "wr = open(results_path + \"test_prediction_\" + base_model + \"_\" + lang + \".txt\", \"w\")    \n",
    "for entry in tqdm(test_loader, total=len(test_data)//test_loader.batch_size, position=0, leave=True):\n",
    "    v_loss, v_pred = evaluate(entry[0], entry[1], entry[2], entry[3], model, mode='test')\n",
    "    test_loss.append(v_loss)\n",
    "    test_pred.append(v_pred)\n",
    "    wr.write(str(v_pred)+\"\\n\")\n",
    "\n",
    "test_loss = np.mean(test_loss)#.item()\n",
    "\n",
    "print(\"Test Loss: \", test_loss)\n",
    "\n",
    "wr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb8b4197-be6d-44f1-b67d-89f8d3834b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv(\"/home/jupyter/data/test_data/bq_test_\" + lang + \"_process_10k.csv\", sep=',')\n",
    "df_test = pd.read_csv(\"/home/jupyter/multilingual/test_data/test_spanish.tsv\", sep='\\t', lineterminator='\\n')\n",
    "# df_test = pd.read_csv(\"/home/jupyter/data/test_data/hx_test.tsv\", sep='\\t')\n",
    "# gt_labels = np.array(df_test['class'])\n",
    "# mp = {'hate':1, 'normal':0}\n",
    "# df_test['label'].replace(mp, inplace=True)\n",
    "gt_labels = np.array(df_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d23d212-69ff-400c-a4e9-36173cae12a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8328    0.8372    0.8350       940\n",
      "           1     0.7664    0.7606    0.7635       660\n",
      "\n",
      "    accuracy                         0.8056      1600\n",
      "   macro avg     0.7996    0.7989    0.7993      1600\n",
      "weighted avg     0.8054    0.8056    0.8055      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(gt_labels, test_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457197b8-1e12-4075-93ff-1202df2296eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(gt_labels, np.array(test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d176ee80-e0b1-4970-a695-4eeb00c93a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent2 - 80.14, 78.44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a4653cd-c1c1-4514-a775-4a399017886d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([1]),\n",
       " array([2]),\n",
       " array([2]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([1]),\n",
       " array([0]),\n",
       " array([0]),\n",
       " array([2]),\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred # 79.43,76.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc709c5-51bd-4946-852a-c2a62b6733c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc08555b-0034-43ff-9f4d-3ca920aa7e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae3c7ee-5139-43e2-a597-9d212b0a5a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b4cc0e-9e66-4eb9-900d-fb245b5412fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "78.52, 76.13 - rob-tws + easymix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48966a8d-94ca-4918-b6ce-9f18c73a81ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "78.84, 76.32 - rob-twh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a9f7e2-906e-403f-ae6e-7e9bdf252b13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cu110.m89",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m89"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
